%% defense.tex
%% Copyright 2022 Tom M. Ragonneau
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Tom M. Ragonneau.
\documentclass{polyu-presentation}
\usepackage{microtype}
\usepackage{booktabs}

% List of hyphenation exceptions for US English
% Source: https://ctan.org/tex-archive/info/digests/tugboat/hyphenex
\input{ushyphex}

% Bibliographical resources
\addbibresource{ragonneau-bib/strings.bib}
\addbibresource{ragonneau-bib/optim.bib}

% Dedicated mathematical macros
\usepackage{xargs}
\newcommand{\auglag}{\mathcal{L}_{\mathsf{A}}}
\newcommand{\auglagalt}{\tilde{\mathcal{L}}_{\mathsf{A}}}
\newcommand{\con}[1][]{c\ifthenelse{\equal{#1}{}}{}{_{#1}}}
\newcommandx{\conm}[2][1={},2={}]{\hat{c}\ifthenelse{\equal{#2}{}}{}{_{#2}}\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\fset}{\Omega}
\newcommand{\ieq}{\mathcal{E}}
\newcommand{\iub}{\mathcal{I}}
\newcommand{\iter}[1][]{x\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\lag}[1][]{\mathcal{L}\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\lagalt}[1][]{\widetilde{\mathcal{L}}\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\lagm}[1][]{\hat{\mathcal{L}}\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\lagp}[1][]{L\ifthenelse{\equal{#1}{}}{}{_{#1}}}
\newcommand{\lm}[1][]{\lambda\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\lpoly}{\mathscr{L}(\R^n)}
\newcommand{\merit}[1][]{\varphi\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\meritm}[1][]{\hat{\varphi}\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\nstep}[1][]{n\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\nstepalt}[1][]{\bar{n}\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\obj}{f}
\newcommand{\objm}[1][]{\hat{f}\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\objmalt}[1][]{\tilde{f}\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\pstep}[1][]{p\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\qpoly}{\mathscr{Q}(\R^n)}
\newcommand{\rad}[1][]{\Delta\ifthenelse{\equal{#1}{}}{}{@\!^{#1}}}
\newcommand{\radlb}[1][]{\delta\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\ratio}[1][]{\rho\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\rstep}[1][]{r\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\sstep}[1][]{s\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\step}[1][]{d\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\tstep}[1][]{t\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\xl}{l}
\newcommand{\xpb}[1][]{\mathcal{P}}
\newcommand{\xpt}[1][]{\mathcal{Y}\ifthenelse{\equal{#1}{}}{}{^{#1}}}
\newcommand{\xsv}[1][]{\mathcal{S}}
\newcommand{\xu}{u}

% If-Then-Else function for pgfplots
\pgfmathdeclarefunction{ifthenelsefpu}{3}{\pgfmathparse{#1*#2 + !#1*#3}}

% Performance and data profiles
\usepackage{xstring}
\newcommand{\drawprofiles}[4]{%
    \def\selectsolvers{#2}%
    \def\selectcsv{figures/#3}%
    \def\selectprofile{#4}%
    \ifthenelse{\equal{#1}{performance}}{%
        \def\selectxlabel{$\log_2(\text{perf.\ ratio})$}%
        \def\selectylabel{Perf.\ profiles ($\tau = 10^{-#4}$)}%
    }{%
        \def\selectxlabel{Number of simplex gradients}%
        \def\selectylabel{Data profiles ($\tau = 10^{-#4}$)}%
    }
    \input{figures/profiles.tex}%
}
\newcommand{\drawperformanceprofiles}[3]{\drawprofiles{performance}{#1}{#2}{#3}}
\newcommand{\drawdataprofiles}[3]{\drawprofiles{data}{#1}{#2}{#3}}

\title[Model-Based DFO Methods and Software]{Model-Based Derivative-Free Optimization Methods and Software}
\subtitle{}
\author[Tom M. Ragonneau]{\texorpdfstring{
    \href{https://www.tomragonneau.com/}{Tom M. Ragonneau}\\
    \footnotesize Co-supervised by Dr.\ \href{https://www.zhangzk.net/}{Zaikun Zhang} and Prof.\ \href{https://www.polyu.edu.hk/ama/staff/xjchen/ChenXJ.htm}{Xiaojun Chen}
}{Tom M. Ragonneau}}
\institute[PolyU AMA]{
    Department of Applied Mathematics\\
    The Hong Kong Polytechnic University
}
\date{December 6, 2022}
\titlegraphic{}

\begin{document}

\begin{frame}
    \frametitle{What is DFO?}
    
	Derivative-free optimization (DFO) aims at solving
    \begin{equation*}
        \min_{\iter \in \fset \subseteq \R^n} \obj(x)
    \end{equation*}
    using only \alert{function values}.
    Typically,~$\obj$ is a \alert{blackbox}.

    \medskip

    \begin{center}
        \begin{tikzpicture}
            \draw[rounded corners,fill] (0,0) rectangle (3,1);
            \draw[-stealth,thick] (-1.5,0.5) -- (0,0.5);
            \draw[-stealth,thick] (3,0.5) -- (4.5,0.5);
            \node[text=white] at (1.5,0.5) {$\obj : \R^n \to \R$};
            \node[left] at (-1.5,0.5) {$\iter \in \R^n$};
            \node[right] at (4.5,0.5) {$\obj(\iter)$};
        \end{tikzpicture}
    \end{center}

    \medskip
    
    \begin{block}{}
        \begin{enumerate}
            \item $f$ may be smooth, but derivatives \alert{cannot} be evaluated.
            \item Each function evaluation is \alert{expensive}.
            \item The dominating \alert{computational cost} is the function evaluations.
            \item Do \alert{not} use DFO if any kind of first order information is available.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Examples of DFO problems}

    \begin{enumerate}
        \item Academic examples
        \begin{enumerate}
            \item Automatic error analysis \parencite{Higham_1993,Higham_2002}
            \item Optimization method tuning \parencite{Audet_Orban_2006}
        \end{enumerate}
        \item Engineering and industrial examples
        \begin{enumerate}
            \item \alert<2>{Hyperparameter tuning} \parencite{Ghanbari_Scheinberg_2017}
            \item \alert<2>{Aircraft engineering}~\parencite{Gazaix_Etal_2019}
            \item Aeroacoustic shape design \parencite{Marsden_2004,Marsden_Etal_2004}
            \item Computational fluid dynamics \parencite{Duvigneau_Visonneau_2004}
            \item Computational nuclear physics \parencite{Eldred_Etal_2022}
        \end{enumerate}
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Hyperparameter tuning in machine learning}

    \begin{center}
        \begin{tikzpicture}
			\uncover<2>{
				\draw[rounded corners,pattern=north east lines,pattern color=DarkOrchid,fill opacity=0.3] (8,3) rectangle (11,4.5);
			}
			\draw[thick,rounded corners] (0,0) rectangle (3,1.5);
			\draw[thick,rounded corners] (0,4) rectangle (3,5.5);
			\draw[thick,rounded corners] (4,2) rectangle (7,3.5);
			\draw[thick,rounded corners] (8,1) rectangle (11,2.5);
			\draw[thick,rounded corners] (8,3) rectangle (11,4.5);
			\draw[thick,-stealth] (3,1) -- (5.5,1) -- (5.5,2);
			\draw[thick] (3,0.5) -- (7.5,0.5) -- (7.5,2.5) -- (7,2.5);
			\draw[thick,-stealth] (7.5,1.75) -- (8,1.75);
			\draw[thick] (3,4.75) -- (7.5,4.75) -- (7.5,3) -- (7,3);
			\draw[thick,-stealth] (7.5,3.75) -- (8,3.75);
			\node at (0.6,0.75) {\includegraphics[height=0.75cm]{images/ml/presentation.png}};
			\node at (0.6,4.75) {\includegraphics[height=0.75cm]{images/ml/search.png}};
			\node at (4.6,2.75) {\includegraphics[height=0.75cm]{images/ml/deep-learning.png}};
			\node at (8.6,1.75) {\includegraphics[height=0.75cm]{images/ml/analysis.png}};
			\node at (8.6,3.75) {\includegraphics[height=0.75cm]{images/ml/analytics.png}};
			\node at (2,0.75) {\makecell{Training\\ dataset}};
			\node at (2,4.75) {\makecell{Testing\\ dataset}};
			\node at (6,2.75) {\makecell{Machine\\ learning}};
			\node at (10,1.75) {\makecell{Training\\ accuracy}};
			\node at (10,3.75) {\makecell{Testing\\ accuracy}};
			\uncover<2>{
				\draw[rounded corners,pattern=north east lines,pattern color=DarkOrchid,fill opacity=0.3] (0,2) rectangle (3,3.5);
				\draw[thick,rounded corners] (0,2) rectangle (3,3.5);
				\draw[thick,-stealth] (3,2.75) -- (4,2.75);
				\node at (0.6,2.75) {\includegraphics[height=0.7cm]{images/ml/admin-panel.png}};
				\node at (2,2.75) {\makecell{Hyper-\\ parameters}};
			}
		\end{tikzpicture}
    \end{center}

    \pause
    \begin{block}{}
        \begin{enumerate}
            \item How to \alert{maximize} the performance by tuning the \alert{hyperparameters}?
            \item What is the \alert{gradient} of the measure of performance?
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Aircraft engine pylon optimization}

    \begin{block}{}
        Where to position the engines to \alert{maximize} the performance of an aircraft?
    \end{block}
    
    \begin{center}
        \begin{tikzpicture}
            \draw[thick,rounded corners,pattern=north east lines,pattern color=DarkOrchid,fill opacity=0.3] (0,0) rectangle (3,1.5);
            \draw[thick,rounded corners] (-4,-2.5) rectangle (-1,-1);
            \draw[thick,rounded corners] (0,-2.5) rectangle (3,-1);
            \draw[thick,rounded corners] (4,-2.5) rectangle (7,-1);
            \draw[thick,dotted,rounded corners,DarkOrchid] (-4.25,-2.75) rectangle (7.25,-0.75);
			\draw[thick,stealth-stealth] (1.5,0) -- (1.5,-1);
			\draw[thick,stealth-stealth] (-2.5,-1) -- (-2.5,-0.5) -- (1,-0.5) -- (1,0);
			\draw[thick,stealth-stealth] (5.5,-1) -- (5.5,-0.5) -- (2,-0.5) -- (2,0);
            \node at (1.5,0.75) {MDO};
            \node at (-2.5,-1.75) {\makecell{Aerodynamic\\ optimization}};
            \node at (1.5,-1.75) {\makecell{OAD\\ optimization}};  % Overall Aircraft Design
            \node at (5.5,-1.75) {\makecell{Structure\\ optimization}};
            \node[below right,text=DarkOrchid] at (-4.25,-2.75) {\small\emph{Different independent disciplines/departments}};
        \end{tikzpicture}
    \end{center}

    \vspace{-\bigskipamount}
    
	\begin{block}{}
        \begin{enumerate}
            \item Each component of the problem involves \alert{simulations}.
            \item The problem is solved using DFO at IRT Saint-Exup{\'{e}}ry (\alert{Airbus}).
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Focus of this thesis}

    There are numerous excellent works in DFO.

    \medskip

    \begin{block}{}
        \begin{enumerate}
            \item \alert{Direct-search methods}: Nelder-Mead \parencite{Nelder_Mead_1965}, MADS \parencite{Audet_Dennis_2006}, BFO \parencite{Porcelli_Toint_2017,Porcelli_Toint_2022}, \dots
            \item \alert{Model-based methods}: WEDGElin \parencite{Marazzi_Nocedal_2002}, MNH \parencite{Wild_2008}, DFO-LS \parencite{Cartis_Etal_2019,Hough_Roberts_2022}, \emph{Powell's DFO methods}, \dots
        \end{enumerate}
    \end{block}

    \medskip

    However, there are still many challenges, e.g.,
    \begin{enumerate}
        \item having \alert{theoretical} understanding of existing DFO techniques,
        \item exploring more advanced \alert{methodologies} in DFO,
        \item designing new DFO \alert{algorithms}, and
        \item producing \alert{software} packages (necessary to make an \alert{impact}, but \alert{hard}).
    \end{enumerate}
\end{frame}

\begin{framenopagination}
    \frametitle{Table of contents}
    
	\tableofcontents[hideallsubsections]
\end{framenopagination}

\section{The PDFO package (\textbf{software})}

\begin{frame}
    \frametitle{Powell's DFO solvers}

    We want to solve
    \begin{equation*}
        \min_{\iter \in \fset \subseteq \R^n} \obj(\iter),
    \end{equation*}
    where derivatives of~$\obj$ (and possibly the constraint functions) are \alert{unknown}.

    \bigskip

    \begin{center}
        \begin{tabular}{@{}lll@{}}
            \toprule
            Solver  & Feasible set~$\Omega$                                 & References\\
            \midrule
            UOBYQA  & $\R^n$                                                & \textcite{Powell_2002}\\
            NEWUOA  & $\R^n$                                                & \textcite{Powell_2006}\\
            BOBYQA  & $\set{x \in \R^n : \xl \le x \le \xu}$                & \textcite{Powell_2009}\\
            LINCOA  & $\set{x \in \R^n : A x \le b}$                        & \textcite{Powell_2015}\\
            COBYLA  & $\set{x \in \R^n : \con[i](x) \ge 0, ~ i \in \iub}$   & \textcite{Powell_1994}\\
            \bottomrule
        \end{tabular}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Powell's DFO solvers (cont'd)}

    They are \alert{not} unknown solvers.
    For example, COBYLA
    \begin{enumerate}
        \item is cited more than \alert{\num{1250} times},
        \item underlies \texttt{scipy.optimize.minimize} in Python,
        \item is used by IRT Saint-Exup{\'{e}}ry (\alert{Airbus}) to solve MDO problems, and
        \item is a \alert{standard benchmark} to assess the performance of new DFO solvers.
    \end{enumerate}

    \bigskip

    \begin{block}{An obstacle to using Powell's DFO solvers}
        Powell implemented them in \alert{Fortran 77} \dots
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{The PDFO package}

    \begin{block}{}
        \alert{PDFO} is a \alert{cross-platform} package interfacing Powell's DFO solvers.
        \begin{enumerate}
            \item PDFO provides \alert{user-friendly} interfaces.
            \item It \alert{preprocesses} the user's inputs.
            \item Several \alert{bugs} in the original Fortran code are \alert{patched} in PDFO.
        \end{enumerate}
    \end{block}

    \begin{enumerate}
        \item The \alert{MATLAB} signature is consistent with \texttt{fmincon}.
        \item The \alert{Python} signature is consistent with \texttt{scipy.optimize.minimize}.
        \item The package has been downloaded more than \alert{\num{40000} times}.
        \item It is included in GEMSEO, an \alert{industrial} software package for MDO.
    \end{enumerate}

    \smallskip
    
	\begin{center}
        \href{https://www.pdfo.net/}{\includegraphics[width=0.7in]{images/qr/pdfo.png}}

        \scriptsize\url{https://www.pdfo.net/}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Numerical experiments using PDFO}

    We consider the \alert{hyperparameter tuning} of an SVM.
    \begin{enumerate}
        \item It has two hyperparameters.
        \item We maximize the \num{5}-fold cross-validation \alert{AUC score}.
        \item We compare PDFO with two standard methods (\alert{RS} and \alert{TPE}).
        \item We run the experiment on two different datasets.
    \end{enumerate}

    \bigskip

    \begin{center}
        \begin{tabular}{@{}cS[table-format=2]S[table-format=5]@{}}
            \toprule
            LIBSVM dataset  & {Dimension}   & {Dataset size}\\
            \midrule
            splice          & 60            & 1000\\
            ijcnn1          & 22            & 49990\\
            \bottomrule
        \end{tabular}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Numerical experiments using PDFO (cont'd)}

    The results on the \enquote{\alert{\only<1>{splice}\only<2>{ijcnn1}}} dataset are summarized below.

    \bigskip

    \begin{center}
        \only<1>{%
            \begin{tabular}{@{}cS[table-format=3]SSS@{}}
                \toprule
                Solver          & {No.\ eval.}  & {AUC score ($10^{-1}$)}   & {Accuracy ($10^{-1}$)}    & {Exec.\ time (\unit{s})}\\
                \midrule
                \bfseries PDFO  & \bfseries 65  & \bfseries 9.57            & \bfseries 9.93            & \bfseries 3.70\\
                RS              & 100           & 6.41                      & 5.30                      & 4.64\\
                RS              & 300           & 7.88                      & 5.30                      & 13.76\\
                TPE             & 100           & 5.00                      & 5.03                      & 4.89\\
                TPE             & 300           & 7.74                      & 5.30                      & 15.73\\
                \bottomrule
            \end{tabular}%
        }%
        \only<2>{%
            \begin{tabular}{@{}cS[table-format=3]SSS@{}}
                \toprule
                Solver          & {No.\ eval.}  & {AUC score ($10^{-1}$)}   & {Accuracy ($10^{-1}$)}    & {Exec. time (\unit{h})}\\
                \midrule
                \bfseries PDFO  & \bfseries 59  & \bfseries 9.94            & \bfseries 9.82            & \bfseries 0.53\\
                RS              & 100           & 9.89                      & 9.77                      & 1.23\\
                RS              & 300           & 9.89                      & 9.77                      & 3.68\\
                TPE             & 100           & 9.89                      & 9.79                      & 1.23\\
                TPE             & 300           & 9.90                      & 9.79                      & 3.49\\
                \bottomrule
            \end{tabular}
        }
    \end{center}
\end{frame}

\section{Understanding a basic technique in DFO (\textbf{theory})}

\begin{frame}
    \frametitle{Interpolation-based methods and~$\Lambda$-poisedness}
    
    \begin{block}{Interpolation-based methods}
        Many DFO methods construct a \alert{model}~$\objm[k]$ of~$\obj$ by \alert{interpolation}, with
        \setlength{\abovedisplayskip}{7pt}
        \setlength{\belowdisplayskip}{7pt}
        \begin{equation*}
            \objm[k](y) = \obj(y), ~ y \in \xpt[k]
        \end{equation*}
        for some \alert{interpolation set}~$\xpt[k] = \set{y^1, y^2, \dots, y^m} \subseteq \R^n$, updated iteratively.
    \end{block}

    The~\alert{$\Lambda$-poisedness} of~$\xpt[k]$ plays a crucial role in bounding the model error.

    \begin{block}{$\Lambda$-poisedness \parencite{Conn_Scheinberg_Vicente_2009b}}
        The set~$\xpt[k]$ is said \alert{$\Lambda$-poised} in a compact set~$\mathcal{C} \subseteq \R^n$ if~\alert{$\Lambda \ge \Lambda_{\mathcal{C}}$}, with
        \setlength{\abovedisplayskip}{7pt}
        \setlength{\belowdisplayskip}{7pt}
        \begin{equation*}
            \Lambda_{\mathcal{C}} = \max_{1 \le i \le m} \max_{\iter \in \mathcal{C}} @@ \abs{\lagp[i](\iter)},
        \end{equation*}
        where~$\lagp[i]$ is the least Frobenius norm \alert{Lagrange polynomial} associated with~$y^i$.
    \end{block}

    Interpolation error analysis indicates that the \alert{lower}~$\Lambda_{\mathcal{C}}$ is, the \alert{better}~$\xpt[k]$ is.
\end{frame}

\begin{frame}
    \frametitle{How to choose the initial interpolation set?}
    
    \begin{block}{}
        $\xpt[k + 1]$ is usually updated from~$\xpt[k]$.
        However, how to \alert{choose}~$\xpt[0]$?
    \end{block}

    \bigskip

    \begin{columns}
        \begin{column}{0.6\textwidth}
            As \textcite{Powell_2006}, assuming that~$\iter[0] = 0$, let
            \begin{empheq}[left={z^j = \empheqlbrace}]{alignat*=2}
                & \textcolor{MidnightBlue}{0}                 && \quad \text{if~$j = 1$,}\\
                & \textcolor{BurntOrange}{\delta e_{j - 1}} && \quad \text{if~$2 \le j \le n + 1$,}\\
                & \textcolor{Maroon}{-\delta e_{j - n - 1}} && \quad \text{if~$n + 2 \le j \le 2n + 1$}
            \end{empheq}
            for some~$\delta > 0$, and define~$\xpt[0]$ to be
            \begin{equation*}
                \mathcal{Z}_m = \set{z^1, z^2, \dots, z^m}
            \end{equation*}
            for some~$m \le 2n + 1$.
        \end{column}
        \begin{column}{0.4\textwidth}
            \begin{center}
                \begin{tikzpicture}
                    \begin{axis}[
                        axis equal image,
                        xtick={-1,0,1},
                        ytick={-1,0,1},
                        xticklabels={$-\delta$,$0$,$\delta$},
                        yticklabels={$-\delta$,$0$,$\delta$},
                        xlabel={$x_1$},
                        ylabel={$x_2$},
                        width=\columnwidth,
                    ]
                        \addplot[only marks,mark options={fill=MidnightBlue}] coordinates {(0, 0)} node[above right,text=MidnightBlue] {$z^1$};
                        \addplot[only marks,mark options={fill=BurntOrange}] coordinates {(1, 0)} node[above,text=BurntOrange] {$z^2$};
                        \addplot[only marks,mark options={fill=BurntOrange}] coordinates {(0, 1)} node[right,text=BurntOrange] {$z^3$};
                        \addplot[only marks,mark options={fill=Maroon}] coordinates {(-1, 0)} node[above,text=Maroon] {$z^4$};
                        \addplot[only marks,mark options={fill=Maroon}] coordinates {(0, -1)} node[right,text=Maroon] {$z^5$};
                        \addplot[no marks] coordinates{(0, 0) (1, 0)};
                        \addplot[no marks] coordinates{(0, 0) (0, 1)};
                        \addplot[no marks] coordinates{(0, 0) (-1, 0)};
                        \addplot[no marks] coordinates{(0, 0) (0, -1)};
                    \end{axis}  
                \end{tikzpicture}
            \end{center}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{Bounds for the~$\Lambda$-poisedness of~$\mathcal{Z}_m$}

    \begin{block}{Theorem~2.5.1.}
        For any~$p \in [1, \infty)$,~$\mathcal{Z}_m$ is~\alert{$\Lambda_p$-poised} in~$\mathcal{B}_p(\delta) = \set{\iter \in \R^n : \norm{\iter}_p \le \delta}$ for some
        \begin{equation*}
            \Lambda_p \in \big[ 1 + (2n + 1 - m)^{\frac{p - 1}{p}},  n \big],
        \end{equation*}
        with~$0^0$ defined as~$0$.
        Moreover, the lower bound is \alert{attained} if~$p \in \set{1, 2}$.
    \end{block}

    \bigskip

    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[
                xtick={22,41},
                xticklabels={$n + 2$,$2n + 1$},
                ytick={1,3,5,7,9},
                xlabel={$m$ (with~$n = 20$)},
                ylabel={Lower bound},
                width=0.9\textwidth,
                height=0.5\textheight,
                samples at={22,...,41},
            ]
                \addplot{ifthenelsefpu((x==41), 1, 2)};
                \addplot{1+(41-x)^(1/2)};
                \addplot{1+(41-x)^(2/3)};
                \addplot{1+(41-x)^(3/4)};
                \addlegendentry{$p = 1$}
                \addlegendentry{$p = 2$}
                \addlegendentry{$p = 3$}
                \addlegendentry{$p = 4$}
            \end{axis}  
        \end{tikzpicture}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Bounds for the~$\Lambda$-poisedness of~$\mathcal{Z}_m$ (cont'd)}

    \emph{Sketch of the proof}.
    \begin{enumerate}
        \item Construct explicit formulae for~$\set{\lagp[i]}_{1 \le i \le m}$.
        \item Show that~$\mathcal{Z}_m$ is~$\Lambda_p$-poised in~$\mathcal{B}_p(\delta)$ with
        \begin{equation*}
            \Lambda_p = \max_{\iter \in \mathcal{B}_p(\delta)} \abs{\lagp[1](\iter)}.
        \end{equation*}
        \item The lower bound is obtained by evaluating~$\abs{\lagp[1](\iter)}$ at a particular~$\iter$.
        \item The upper bound follows~$\mathcal{B}_p(\delta) \subseteq \mathcal{B}_{\infty}(\delta)$ so that~$\Lambda_p \le \Lambda_{\infty}$ with
        \begin{equation*}
            \Lambda_{\infty} = \max \set{2n + 2 - m, n - 1} \le n.
        \end{equation*}
    \end{enumerate}

    \medskip

    In particular, we can show that for~$p \in [1, 2]$ and~$m = 2n + 1$, we have~$\Lambda_p = 1$.

    \medskip

    \begin{block}{}
        For any~$p \in [1, 2]$,~$\Lambda_p$ attains its \alert{minimum} for~$\mathcal{Z}_m$ when~$m = 2n + 1$.
    \end{block}
\end{frame}

\section{New perspectives and developments on SQP (\textbf{theory} and \textbf{methodology})}

\begin{frame}
    \frametitle{The Sequential Quadratic Programming (SQP) method}

    We consider the \alert{derivative-based} optimization problem
    \setlength{\abovedisplayskip}{7pt}
    \setlength{\belowdisplayskip}{7pt}
    \begin{align*}
        \min_{\iter \in \R^n}   & \quad \obj(\iter)\\
        \text{s.t.}             & \quad \con(\iter) \le 0.
    \end{align*}
	Given~$\iter[k] \in \R^n$, the \alert{SQP method} finds~$\step[k]$ by solving approximately
    \begin{align*}
        \min_{\step \in \R^n}   & \quad \nabla \obj(\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lag(\iter[k], \lm[k]) \step\\
        \text{s.t.}             & \quad \con(\iter[k]) + \nabla \con(\iter[k]) \step \le 0
    \end{align*}
    for some~$\lm[k]$, where~$\lag$ denotes the \alert{Lagrangian}, and sets~$\iter[k + 1] = \iter[k] + \step[k]$.

    \begin{block}{}
        \begin{enumerate}
            \item It is proposed by \textcite{Wilson_1963,Han_1976,Han_1977,Powell_1978a,Powell_1978b,Powell_1978c}.
            \item It is closely related to a \alert{Newton} method for the KKT system.
            \item Does it work if~$\nabla_{x, x}^2 \lag(\iter[k], \lm[k])$ is replaced with~$\nabla^2 \obj(\iter[k])$?
            \pause
            \alert{No}.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{A new interpretation of the SQP subproblem}
    
	\begin{enumerate}
        \item Assume for simplicity that the constraints are~$\con(\iter) = 0$.
        \item For some~$\bar{\iter}$ and~$\bar{\lm}$, define
        \setlength{\belowdisplayskip}{8pt}
        \begin{equation*}
            Q(\step) = \obj(\bar{\iter}) + \nabla \obj(\bar{\iter})^{\T} \step + \frac{1}{2} \step^{\T} \only<1>{\textcolor{MidnightBlue}{\nabla_{x, x}^2 \lag(\bar{\iter}, \bar{\lm})}}\only<2>{\textcolor{BurntOrange}{\nabla^2 \obj(\bar{\iter})}} \step.
        \end{equation*}
    \end{enumerate}

    \begin{block}{Theorem~4.1.1.}
        Consider a \alert{curve} parametrized by~$\iter : \R \to \R^n$ satisfying
        \begin{equation*}
            c\big(\iter(t)\big) = c(\bar{\iter}) \quad \text{for all~$t \in \R$}, \quad \text{and} \quad \iter(0) = \bar{\iter}.
        \end{equation*}
        Under some regularity assumptions, there exist~$\nu \ge 0$ and~$\epsilon > 0$ such that
        \begin{equation*}
            \abs[\big]{\obj\big(\iter(t)\big) - Q\big(\iter'(0) t\big)} \le \bigg(\nu t + \frac{1}{2} \abs[\big]{\iter''(0)^{\T} \only<1>{\textcolor{MidnightBlue}{\big[\nabla \obj(\bar{\iter}) + \nabla c(\bar{\iter})^{\T} \bar{\lm} \big]}}\only<2>{\textcolor{BurntOrange}{\nabla \obj(\bar{\iter})}}} \bigg) t^2,
        \end{equation*}
        for all~$t \in (-\epsilon, \epsilon)$.
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{A new interpretation of the SQP subproblem (cont'd)}

    \emph{Sketch of the proof}.
    \begin{enumerate}
        \item With~$\phi = \obj \circ \iter$ and~$\hat{\phi}$ its second-order Maclaurin expansion, we have
        \begin{equation*}
            \abs[\big]{\obj \big(\iter(t) \big) - Q(\iter'(0) t)} \le \underbrace{\abs[\big]{\phi(t) - \hat{\phi}(t)}}_{\le \nu t^3} + \abs[\big]{\hat{\phi}(t) - Q(\iter'(0) t)}.
        \end{equation*}
        \item Show by direct calculations that
        \begin{equation*}
            \abs[\big]{\hat{\phi}(t) - Q(\iter'(0) t)} = \frac{t^2}{2} \abs[\bigg]{\iter''(0)^{\T} \nabla \obj(\bar{\iter}) - \sum_i \bar{\lm}_i \iter'(0) \nabla^2 \con[i](\bar{\iter}) \iter'(0)}.
        \end{equation*}
        \item Note that~$\con \circ x$ is a constant, so that
        \begin{equation*}
            0 = \frac{\du^2}{\du t^2} \con[i] \big( \iter(t) \big) \bigg\vert_{t = 0} = \iter'(0)^{\T} \nabla^2 \con[i](\bar{\iter}) \iter'(0) + \iter''(0)^{\T} \nabla \con[i](\bar{\iter}).
        \end{equation*}
        \item The result is obtained by combining these three facts.
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{The trust-region SQP method}
    
	\begin{block}{}
        \begin{enumerate}
            \item The convergence properties of the SQP method are \alert{local}.
            \item We employ the \alert{trust-region} framework as a globalization strategy.
        \end{enumerate}
    \end{block}

    Given an iterate~$\iter[k] \in \R^n$, let~$\step[k]$ be an approximate solution to
    \begin{align*}
        \min_{\step \in \R^n}   & \quad \nabla \obj(\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lag(\iter[k], \lm[k]) \step\\
        \text{s.t.}             & \quad \con(\iter[k]) + \nabla \con(\iter[k]) \step \le 0,\\
                                & \quad \textcolor{MidnightBlue}{\norm{\step} \le \rad[k]}
    \end{align*}
    for some~$\lm[k]$ and~$\rad[k] > 0$.
    Given a \alert{merit function}~$\merit$, we then set
    \begin{empheq}[left={\iter[k + 1] = \empheqlbrace}]{alignat*=2}
        & \iter[k] + \step[k]   && \quad \text{if~$\merit(\iter[k] + \step[k]) < \merit(\iter[k])$,}\\
        & \iter[k]              && \quad \text{otherwise.}
    \end{empheq}

    How to \alert{solve} the subproblem?
    What if it is \alert{infeasible}?
\end{frame}

\begin{frame}
    \frametitle{A new \citeauthor{Byrd_1987}-\citeauthor{Omojokun_1989} approach}

    We compute the \alert{trial step}~$\step[k]$ as~$\step[k] = \nstep[k] + \tstep[k]$, where
    \begin{enumerate}
        \item the \alert{normal step}~$\nstep[k]$ reduces the (possible) constraint violation, and
        \item the \alert{tangential step}~$\tstep[k]$ reduces the objective function of the subproblem.
    \end{enumerate}
    
    \begin{columns}
        \begin{column}{0.45\textwidth}
            \begin{center}
                \begin{tikzpicture}[scale=0.85]
                    % Linear constraints
                    \uncover<1,2,6->{\fill[color=RoyalBlue,opacity=0.4] (-4,-1) -- (-1.5,-1) -- (-0.5,4) -- (-4,4) -- cycle;}
                    \uncover<3-5>{\fill[color=RoyalBlue,opacity=0.4] (-4,-1) -- (-2.1,-1) -- (-1.1,4) -- (-4,4) -- cycle;}
                    \uncover<1,2,6>{\fill[color=RoyalBlue,opacity=0.4] (-4,1) -- (0,4) -- (-4,4) -- cycle;}
                    \uncover<3-5,7->{\fill[color=RoyalBlue,opacity=0.4] (-4,0.125) -- (1,3.875) -- (1,4) -- (-4,4) -- cycle;}
        
                    % Trust regions
                    \begin{scope}
                        \clip (-4,-1) rectangle (1,4);
                        \draw[fill=Dandelion,draw opacity=0.7,fill opacity=0.5] (0,0) circle (3);
                        \draw[densely dotted,fill=Dandelion,opacity=0.7] (0,0) circle (2.5);
                    \end{scope}
        
                    % Feasible region for the tangential subproblem
                    \begin{scope}
                        \clip (-4,0.125) -- (-1.5,2) -- (-1.1,4) -- (-4,4) -- cycle;
                        \uncover<4-5,10>{\fill[pattern=north west lines,opacity=0.7] (0,0) circle (3);}
                    \end{scope}
                    \begin{scope}
                        \clip (-4,0.125) -- (-27/34,43/17) -- (-0.5,4) -- (-4,4) -- cycle;
                        \uncover<8,9>{\fill[pattern=north west lines,opacity=0.7] (0,0) circle (3);}
                    \end{scope}
                    \begin{scope}
                        \clip (-1.5,2) -- (-1.1,4) -- (-0.5,4) -- (-27/34,43/17) -- cycle;
                        \uncover<10>{
                            \fill[pattern=crosshatch,opacity=0.7] (0,0) circle (3);
                            \draw[thick,opacity=0.7] (-1.5,2) -- (-1.365785,2.671073);
                            }
                    \end{scope}
        
                    % Frame and annotations
                    \uncover<5>{
                        \draw[-stealth,thick,MidnightBlue] (-1.5,2) -- (-2.2,1.7);
                        \node[below,xshift=9pt,text=MidnightBlue] at (-1.85,1.85) {$\tstep[k]$};
                        \draw[-stealth,thick] (0,0) -- (-2.2,1.7);
                        \node[below left] at (-1.1,0.85) {$\step[k]$};
                    }
                    \uncover<9>{
                        \draw[-stealth,thick,MidnightBlue] (-1.5,2) -- (-0.9,2.7);
                        \node[below,xshift=5pt,text=MidnightBlue] at (-1.2,2.35) {$\tstep[k]$};
                        \draw[-stealth,thick] (0,0) -- (-0.9,2.7);
                        \node[above right] at (-0.45,1.35) {$\step[k]$};
                    }
                    \uncover<2->{\draw[-stealth,thick,Mahogany] (0,0) -- (-1.5,2);}
                    \uncover<2-5>{\node[above right,text=Mahogany] at (-0.75,1) {$\nstep[k]$};}
                    \uncover<6->{\node[below left,text=Mahogany] at (-0.75,1) {$\nstep[k]$};}
                    \draw[fill] (0,0) circle (1.4pt) node[below right] {$\iter[k]$};
                    \draw[thick] (-4,-1) rectangle (1,4);
                \end{tikzpicture}
            \end{center}
        \end{column}
        \begin{column}{0.55\textwidth}
            \begin{tikzpicture}
                \draw[fill=Dandelion,draw opacity=0.7,fill opacity=0.5] (0,0) circle (.2);
                \node[right] at (.4,0) {Trust region};
                \draw[densely dotted,fill=Dandelion,opacity=0.7] (0,-0.6) circle (.2);
                \node[right] at (.4,-0.6) {Reduced trust region};
                \fill[color=RoyalBlue,opacity=0.4] (-.2,-1.4) rectangle (.2,-1);
                \node[right] at (.4,-1.2) {Linear constraints};
                \uncover<4->{
                    \fill[pattern=north west lines,opacity=0.7] (-.2,-2) rectangle (.2,-1.6);
                    \node[right] at (.4,-1.8) {Feasible region for~$\tstep[k]$};
                }
                \uncover<10>{
                    \fill[pattern=north east lines,opacity=0.7] (-.2,-2.6) rectangle (.2,-2.2);
                    \node[right] at (.4,-2.4) {Extra feasible region for~$\tstep[k]$};
                }
            \end{tikzpicture}

            \bigskip

            The \alert<1-5>{standard} approach vs.\ our \alert<6->{new} one.
        \end{column}
    \end{columns}

    \medskip

    \uncover<10>{
        \begin{enumerate}
            \item The feasible region for~$\tstep[k]$ is \alert{wider} in the new approach.
            \item The new approach works \alert{evidently better} in our experiments.
        \end{enumerate}
    }
\end{frame}

\begin{frame}
    \frametitle{A new \citeauthor{Byrd_1987}-\citeauthor{Omojokun_1989} approach (cont'd)}

    The mathematics of \only<1>{the \textcolor{BurntOrange}{\textbf{standard}}}\only<2>{our \textcolor{MidnightBlue}{\textbf{new}}} approach are as follows.

    \smallskip

    \begin{enumerate}
        \item The \alert{normal step}~$\nstep[k]$ solves approximately
        \begin{align*}
            \min_{\step \in \R^n}   & \quad \norm[\big]{\posp{\con(\iter[k]) + \nabla \con(\iter[k]) \step}}\\
            \text{s.t.}             & \quad \norm{\step} \le \zeta \rad[k]
        \end{align*}
        for some~$\zeta \in (0, 1)$.
        \item The \alert{tangential step}~$\tstep[k]$ solves approximately
        \begin{align*}
            \min_{\step \in \R^n}   & \quad \big[ \nabla \obj(\iter[k]) + \nabla_{x, x}^2 \lag(\iter[k], \lm[k]) \nstep[k] \big]^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lag(\iter[k], \lm[k]) \step\\
            \text{s.t.}             & \quad \nabla \con(\iter[k])^{\T} \step \le \only<1>{\textcolor{BurntOrange}{0}}\only<2>{\textcolor{MidnightBlue}{\negp{- \con(\iter[k]) - \nabla \con(\iter[k]) \nstep[k]}}},\\
                                    & \quad \norm{\nstep[k] + \step} \le \rad[k].
        \end{align*}
    \end{enumerate}
\end{frame}

\section{COBYQA \textemdash\ A trust-region SQP DFO method (\textbf{algorithm} and \textbf{software})}

\begin{frame}
    \frametitle{The problem addressed by COBYQA}
    
	We design a method named \alert{COBYQA} to solve
    \begin{align*}
        \min_{x \in \R^n}   & \quad \obj(x)\\
        \text{s.t.}         & \quad \con(x) \le 0,\\
                            & \quad \xl \le x \le \xu,
    \end{align*}
    where derivatives of~$\obj$ and~$\con$ are \alert{unknown}.

    \bigskip

    \begin{block}{}
        \begin{enumerate}
            \item The method also accepts \alert{equality constraints}.
            \item The bound constraints are handled separately.
            \item Our goal is to design a \alert{successor} for COBYLA.
            \item We do not only design COBYQA but also \alert{implement} it into a solver.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Why inviolable bound constraints?}
    
	\begin{block}{}
        We assume that the bound constraints~$\xl \le x \le \xu$ are \alert{inviolable}.
        \begin{enumerate}
            \item They often represent inalienable \alert{physical} or \alert{theoretical} restrictions.
            \item $f$ and/or~$\con$ may \alert{not} be defined otherwise.
            \item COBYQA \alert{always} respects the bound constraints.
        \end{enumerate}
    \end{block}

    \bigskip

    The two examples of DFO problems we detailed have inviolable bounds.
    \begin{enumerate}
        \item Hyperparameters in machine learning often admit inviolable bounds.
        \item Aircraft engine pylons must be beneath the wings.
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Interpolation-based quadratic models}
    
	We model~$\obj$ by \alert{quadratic} interpolation using the derivative-free \alert{PSB} update.

    \medskip

    \begin{block}{Derivative-free symmetric Broyden update \parencite{Powell_2004b}}
        For each~$k = 0, 1, \dots$, the model~$\objm[k]$ of~$\obj$ solves
        \begin{align*}
            \min_{Q}    & \quad \textcolor{MidnightBlue}{\norm[\big]{\nabla^2 \objm[k - 1] - \nabla^2 Q}_{\mathsf{F}}}\\
            \text{s.t.} & \quad Q(y) = \obj(y), ~ y \in \xpt[k],
        \end{align*}
        where~$\objm[-1] = 0$ and~$\xpt[k] \subseteq \R^n$ satisfies
        \begin{equation*}
            n + 2 \le \card(\xpt[k]) \le \frac{1}{2} (n + 1) (n + 2).
        \end{equation*}
    \end{block}

    \medskip

    Similarly, we build the quadratic models~$\conm[0], \conm[1], \dots$, of~$\con$.
\end{frame}

\begin{frame}
    \frametitle{The derivative-free trust-region SQP method}

    Given an iterate~$\iter[k] \in \R^n$, our \alert{trust-region} subproblem is
    \begin{align*}
        \min_{\step \in \R^n}   & \quad \nabla \objm[k](\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step\\
        \text{s.t.}             & \quad \conm[k](\iter[k]) + \nabla \conm[k](\iter[k]) \step \le 0,\\
                                & \quad \norm{\step} \le \rad[k]
    \end{align*}
    for some~$\lm[k]$ and~$\rad[k] > 0$, where~$\lagm[k](\iter, \lm) = \objm[k](\iter) + \lm^{\T} \conm[k](\iter)$.

    \bigskip

    \begin{block}{}
        \begin{enumerate}
            \item The subproblem is solved using our new \alert{Byrd-Omojokun} approach.
            \item Usually,~$\iter[k] + \step[k]$ replaces a point in~$\xpt[k]$ to build~$\xpt[k + 1]$.
            \item The \alert{trust-region radius} is updated as in the Powell's DFO methods.
        \end{enumerate}
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{A lot of questions need to be answered}

    \begin{enumerate}
        \item How to calculate the steps~$\nstep[k]$ and~$\tstep[k]$ numerically?\\
        \textcolor{MidnightBlue}{COBYQA uses adaptations of the truncated conjugate gradient method.}
        \item What is the approximate Lagrange multiplier~$\lm[k]$?\\
        \textcolor{MidnightBlue}{\textit{We choose the least-squares Lagrange multiplier.}}
        \item Which merit function should we use?\\
        \textcolor{MidnightBlue}{\textit{COBYQA uses the~$\ell_2$-merit function.}}
        \item How to update the penalty parameter?\\
        \textcolor{MidnightBlue}{\textit{The update incorporates}}
        \begin{enumerate}
            \item \textcolor{MidnightBlue}{\textit{a theoretical value for the exactness of the merit function, and}}
            \item \textcolor{MidnightBlue}{\textit{a strategy used by Powell in COBYLA.}}
        \end{enumerate}
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{A central difficulty in the implementation}
    
    \begin{enumerate}
        \setcounter{enumi}{4}
        \item What if the interpolation set~$\xpt[k]$ is almost nonpoised?\\
        \textcolor{Mahogany}{\textit{This is a central difficulty in the implementation of DFO methods.}}
    \end{enumerate}

    \bigskip

    \begin{center}
        \begin{tikzpicture}
            \draw[thick,rounded corners] (0,0) rectangle (3,1.5);
            \draw[thick,rounded corners] (6,0) rectangle (9,1.5);
            \draw[thick,Mahogany] (3,1) -- (4.4,1);
            \draw[-stealth,thick,Mahogany] (4.6,1) -- (6,1);
            \draw[thick,Mahogany] (4.3,0.9) -- (4.5,1.1);
            \draw[thick,Mahogany] (4.5,0.9) -- (4.7,1.1);
            \draw[thick,Mahogany] (6,0.5) -- (4.6,0.5);
            \draw[-stealth,thick,Mahogany] (4.4,0.5) -- (3,0.5);
            \draw[thick,Mahogany] (4.3,0.4) -- (4.5,0.6);
            \draw[thick,Mahogany] (4.5,0.4) -- (4.7,0.6);
            \node at (1.5,0.75) {\makecell{Model\\ management}};
            \node at (7.5,0.75) {\makecell{Optimization\\ process}};
            \node[above,text=Mahogany] at (4.5,1.1) {\small\emph{Often inhibit}};
            \node[below,text=Mahogany] at (4.5,0.4) {\small\emph{each other}};
        \end{tikzpicture}
    \end{center}

    \bigskip

    Chapters~5 and~6 of the thesis address these questions in detail.
\end{frame}

\begin{frame}
    \frametitle{The Python implementation of COBYQA}

    \begin{block}{}
        \textcite{Powell_2006} wrote
        \begin{quote}
            \enquote{The development of NEWUOA has taken nearly \alert{three years}. The work was very \alert{frustrating} [...]}
        \end{quote}
        The development of COBYQA was \alert{not easier}.
    \end{block}

    We implemented COBYQA in \alert{Python} and made it \alert{publicly available}.
    
	\begin{center}
        \href{https://www.cobyqa.com/}{\includegraphics[width=0.7in]{images/qr/cobyqa.png}}

        \scriptsize\url{https://www.cobyqa.com/}
    \end{center}

    It will be soon included in
    \begin{enumerate}
        \item PDFO as a successor for COBYLA, and
        \item GEMSEO as an optimization engine.
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Comparing COBYQA with existing DFO solvers}
    
	\begin{enumerate}
        \item We assess the quality of points based on
        \begin{empheq}[left={\merit(\iter) = \empheqlbrace}]{alignat*=2}
            & \obj(\iter)                           && \quad \text{if~$v_{\infty}(x) \le 10^{-10}$,}\\
            & \infty                                && \quad \text{if~$v_{\infty}(x) \ge 10^{-5}$,}\\
            & \obj(\iter) + 10^5 v_{\infty}(\iter)  && \quad \text{otherwise,}
        \end{empheq}
        where~$v_{\infty}$ denotes the~$\ell_{\infty}$-constraint violation.
        \item The problems are from the \alert{CUTEst} set.
        \item The problems are of \alert{dimension} at most \num{50} (this is \alert{not} small).
        \item The noisy problems replace~$\obj$ with
        \begin{equation*}
            \tilde{\obj}(x) = [1 + \epsilon(\iter)] \obj(\iter),
        \end{equation*}
        where~$\epsilon(x) \sim N(0, \sigma^2)$.
        % \item We show the performance profiles for the tolerance~$\tau = 10^{-4}$.
        % \item For problems with \alert{inviolable} bounds, we set
        % \begin{equation*}
        %     \obj(\iter) = \infty \quad \text{if~$\xl \nleq \iter$ or~$\iter \nleq \xu$,}
        % \end{equation*}
        % so that methods that do not respect the bounds do not break down.
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Performance on bound-constrained problems}

    We compare COBYQA, COBYLA, and two implementations of BOBYQA on
    \begin{enumerate}[<+->]
        \item \alert{bound-constrained} problems,
        \item adding \alert{noise} to~$\obj$, with~$\sigma = 10^{-3}$.
    \end{enumerate}

    \medskip

    \begin{center}
        \only<1>{\drawperformanceprofiles{{"COBYQA","BOBYQA","COBYLA","PY-BOBYQA"}}{plain-1-50-perf-bobyqa-cobyla-cobyqa-py-bobyqa-b.csv}{4}}%
        \only<2>{\drawperformanceprofiles{{"COBYQA","BOBYQA","COBYLA","PY-BOBYQA"}}{noisy-1-50-3-perf-bobyqa-cobyla-cobyqa-py-bobyqa-b.csv}{2}}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Performance on nonlinearly constrained problems}

    We compare COBYQA and COBYLA on
    \begin{enumerate}[<+->]
        \item \alert{nonlinearly constrained} problems,
        \item adding \alert{noise} to~$\obj$, with~$\sigma = 10^{-3}$.
    \end{enumerate}

    \medskip

    \begin{center}
        \only<1>{\drawperformanceprofiles{{"COBYQA","COBYLA"}}{plain-1-50-perf-cobyla-cobyqa-qo.csv}{4}}%
        \only<2>{\drawperformanceprofiles{{"COBYQA","COBYLA"}}{noisy-1-50-6-perf-cobyla-cobyqa-qo.csv}{2}}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Comparison with COBYLA}

    We compare COBYQA and COBYLA on \alert{all} problems.

    \bigskip

    \begin{center}
        \drawperformanceprofiles{{"COBYQA","COBYLA"}}{plain-1-50-perf-cobyla-cobyqa-ubnlqo.csv}{4}
    \end{center}
\end{frame}

\section{Conclusion and future research directions}

\begin{frame}
    \frametitle{Conclusion}

	We presented the following.
    \begin{enumerate}
        \item \alert{PDFO}, a new interface for using Powell's DFO solvers.
        \item A theory on the \alert{optimality} of a particular interpolation set.
        \item New perspectives and developments in the \alert{SQP method}.
        \item A new DFO algorithm \alert{COBYQA} and its implementation.
    \end{enumerate}

    Comments from Dr.\ Gallard (leader of the MDO team at IRT Saint-Exup{\'{e}}ry):

    \begin{block}{}
        \begin{quote}
            \small\enquote{%
            I wish you good luck in this hard and \alert{important} work.
            Yes, I can confirm your work is very \alert{helpful}.}
        \end{quote}
    \end{block}

    \begin{block}{}
        \begin{quote}
            \small\enquote{%
                I have given it a try and compared with COBYLA on some problems we have (without derivatives), it is \alert{significantly faster}, provides a better convergence.
                [\dots] The fact that it is based on SQP will certainly provide a better handling of the general constraints, which was a weakness of COBYLA.}
        \end{quote}
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Future research directions}

    Our thesis prompts several interesting future research directions.\\
    We provide below two examples.
    \begin{enumerate}
        \item Study the \alert{convergence} properties of COBYQA.
        \begin{enumerate}
            \item We followed Powell's philosophy when developing COBYQA.
            \item Establish the global convergence and convergence rate of the method.
            \item Could we simultaneously have results for COBYLA?
        \end{enumerate}
        \item Look into the \alert{implications} of our new result on the SQP subproblem.
        \begin{enumerate}
            \item Can it provide on insights into \alert{manifold optimization}?
            \item Can these insights help the analysis of COBYQA?
        \end{enumerate}
        % \item Improve further the \alert{implementation} of COBYQA.
        % \begin{enumerate}
        %     \item The implementation is very complex due to the nature of DFO.
        %     \item How to make it as performant as LINCOA on linearly constrained problems?
        %     \item Implement it in modern Fortran (F2018 or above).
        % \end{enumerate}
    \end{enumerate}
\end{frame}

\appendix

\begin{frame}[t,allowframebreaks]
    \frametitle{References}

	\printbibliography
\end{frame}

\begin{frame}
    \frametitle{Hyperparameter tuning of an SVM}

    A \alert{binary SVM} classifier~$\delta(x) = \sgn(\beta + \omega^{\T} \psi(x))$ can be obtained by solving
    \begin{align*}
        \min_{(\omega, \beta, \xi) \in \R^{\ell} \times \R \times \R^m} & \quad\frac{1}{2} \norm{\omega}_2^2 + C \norm{\xi}_1\\
        \text{s.t.}                                                     & \quad y_i (\beta + \omega^{\T} \psi(x_i)) \ge 1 - \xi_i, ~ i = 1, 2, \dots, m,\\
                                                                        & \quad \xi \ge 0,
    \end{align*}
    for a \alert{training dataset}~$\set{(x_i, y_i)}_{i = 1}^m \subseteq \R^n \times \set{\pm 1}$ and some~$\psi : \R^n \to \R^{\ell}$.\\
    In our experiments, we have
    \begin{equation*}
        \psi(x_i)^{\T} \psi(x_j) = \exp(-\gamma \norm{x_i - x_j})^2,
    \end{equation*}
    and the \alert{hyperparameters} we consider are~$C$ and~$\gamma$.
\end{frame}

\begin{frame}
    \frametitle{Hyperparameter tuning using COBYQA}

    The results on the \enquote{\alert{\only<1>{splice}\only<2>{ijcnn1}}} dataset are summarized below.

    \bigskip

    \begin{center}
        \only<1>{%
            \begin{tabular}{@{}cS[table-format=3]SSS@{}}
                \toprule
                Solver          & {No.\ eval.}  & {AUC score ($10^{-1}$)}   & {Accuracy ($10^{-1}$)}    & {Exec.\ time (\unit{s})}\\
                \midrule
                COBYQA          & \bfseries 25  & 5.269                     & 5.300                     & \bfseries 3.037\\
                \bfseries PDFO  & 65            & \bfseries 9.568           & \bfseries 9.933           & 3.697\\
                RS              & 100           & 6.409                     & 5.300                     & 4.635\\
                RS              & 300           & 7.880                     & 5.300                     & 13.763\\
                TPE             & 100           & 5.000                     & 5.033                     & 4.889\\
                TPE             & 300           & 7.736                     & 5.300                     & 15.726\\
                \bottomrule
            \end{tabular}%
        }%
        \only<2>{%
            \begin{tabular}{@{}cS[table-format=3]SSS@{}}
                \toprule
                Solver              & {No.\ eval.}  & {AUC score ($10^{-1}$)}   & {Accuracy ($10^{-1}$)}    & {Exec. time (\unit{h})}\\
                \midrule
                \bfseries COBYQA    & \bfseries 48  & 9.896                     & 9.779                     & \bfseries 0.453\\
                PDFO                & 59            & \bfseries 9.940           & \bfseries 9.819           & 0.526\\
                RS                  & 100           & 9.886                     & 9.773                     & 1.231\\
                RS                  & 300           & 9.886                     & 9.773                     & 3.681\\
                TPE                 & 100           & 9.891                     & 9.791                     & 1.230\\
                TPE                 & 300           & 9.896                     & 9.786                     & 3.487\\
                \bottomrule
            \end{tabular}
        }
    \end{center}
\end{frame}

\end{document}
